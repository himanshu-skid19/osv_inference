"""
Phase 1 inference ablation: z_hat features + cosine similarity scoring.

Existing pipeline (run_inference.py):
    patch GAP (384-dim, encoder only)  +  Mahalanobis distance

This script:
    z_hat (128-dim projected CLS, L2-normalised)  +  cosine similarity

Three scoring variants evaluated side-by-side:

    mean_cosine    (1/R) * Σ_r cos(z_q, z_r)
                   Primary fix.  No free parameters.

    softmax_cosine Σ_r softmax(cos(z_q, z_r) / |τ_agg|) · cos(z_q, z_r)
                   Downweights outlier references.  Uses trained τ_agg.

    proto_cosine   cos(z_q,  normalise(mean(z_refs)))
                   Compares to a single normalised prototype.
                   Equivalent to mean_cosine only when R → ∞.

No retraining.  No changes to existing code.

How to interpret results
------------------------
Compare EERs here against run_inference.py output.
The difference estimates how much error comes from the feature/metric mismatch
versus genuine encoder capacity limitations.

Usage
-----
    python run_cosine_inference.py
"""

import json
import os
import sys
from collections import defaultdict
from datetime import datetime

import numpy as np
import torch
import torch.nn.functional as F

# ── Imports from sibling packages ─────────────────────────────────────────────
sys.path.insert(0, os.path.join(os.path.dirname(os.path.abspath(__file__)),
                                '..', 'osv_finetuning'))
from vit   import ViTEncoder
from model import ProjectionHead, BNProjectionHead
from lora  import inject_lora

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
from evaluate import compute_eer, aggregate

sys.path.insert(0, os.path.join(os.path.dirname(os.path.abspath(__file__)),
                                '..', 'writer_enrollment'))
from gasf_feather_mixing import generate_feathered_pseudo_image


# ══════════════════════════════════════════════════════════════════════════════
# CONFIGURATION
# ══════════════════════════════════════════════════════════════════════════════

CHECKPOINT_PATH = (
    r"C:\Users\Himanshu Singhal\Desktop\BTP"
    r"\osv_finetuning\finetune_runs\run_20260224_194757"
    r"\finetuned_full_weights.pth"
)

TEST_DATA_PATH = (
    r"C:\Users\Himanshu Singhal\Desktop\BTP"
    r"\vit_pretraining\deepsigndb_asymmetric_gasf_test.npz"
)

OUTPUT_DIR = r"C:\Users\Himanshu Singhal\Desktop\BTP\inference\results_cosine"

# Must match the value used during enrollment / run_inference.py
R_ENROLL = 4

# Encoder architecture — must match the checkpoint.
# NUM_HEADS cannot be inferred from weights; set it to match your run_finetune.py.
# All other architecture values are inferred automatically from the state dict.
NUM_HEADS = 12    # MAESmall (embed_dim=384); check run_finetune.py if uncertain

# Batch size for encoding (reduce if OOM)
ENCODE_BATCH_SIZE = 128

# ── Feather mixing ─────────────────────────────────────────────────────────────
# When True, augments each writer's enrollment set with N_SYNTHETIC pseudo-images
# generated by randomly sampling patches from the R real references and softening
# patch boundaries with a feathering mask.  Adds feather_* variants to results.
USE_FEATHER_MIXING = True
N_SYNTHETIC        = 18       # pseudo-images to generate per writer
FEATHER_MARGIN     = None     # None → auto (patch_size // 4); or set an int

# ══════════════════════════════════════════════════════════════════════════════


# ─────────────────────────────────────────────────────────────────────────────
# Model loading
# ─────────────────────────────────────────────────────────────────────────────

def load_model(checkpoint_path: str, device: torch.device):
    """
    Load encoder + proj_head + tau_agg from finetuned_full_weights.pth.

    Architecture (embed_dim, num_layers, mlp_dim, img_size, patch_size,
    in_channels, proj_dim) is inferred directly from the state dicts so
    this function is robust to different run configs.

    Returns:
        encoder   : ViTEncoder in eval mode on device
        proj_head : ProjectionHead in eval mode on device
        tau_agg   : float  (trained aggregation temperature, used as |tau_agg|)
    """
    ckpt = torch.load(checkpoint_path, map_location=device)

    # ── Handle two checkpoint formats ─────────────────────────────────────────
    # finetuned_full_weights.pth  → keys: 'encoder', 'proj_head', 'tau_agg'
    # best_model / checkpoint_epoch_*.pth → key: 'model' (full OSVFinetuner
    #   state dict with prefixes encoder.*, proj_head.*, log_tau, tau_agg)
    if 'encoder' in ckpt:
        enc_state  = ckpt['encoder']
        head_state = ckpt['proj_head']
        _tau_agg_raw = ckpt['tau_agg']
    else:
        flat = ckpt['model']
        enc_state  = {k[len('encoder.'):]: v
                      for k, v in flat.items() if k.startswith('encoder.')}
        head_state = {k[len('proj_head.'):]: v
                      for k, v in flat.items() if k.startswith('proj_head.')}
        _tau_agg_raw = flat['tau_agg']

    # ── Infer encoder architecture from state dict ────────────────────────────
    embed_dim  = enc_state['cls_token'].shape[-1]
    num_layers = max(
        int(k.split('.')[1]) for k in enc_state if k.startswith('blocks.')
    ) + 1
    # fc1 may be wrapped by LoRALinear (key: ...fc1.linear.weight) or plain (key: ...fc1.weight)
    _fc1_key = (
        'blocks.0.mlp.fc1.linear.weight'
        if 'blocks.0.mlp.fc1.linear.weight' in enc_state
        else 'blocks.0.mlp.fc1.weight'
    )
    mlp_dim    = enc_state[_fc1_key].shape[0]
    num_patches = enc_state['pos_embed'].shape[1] - 1   # subtract CLS token

    # img_size * patch_size: prefer args.json, fall back to embedded 'args' in
    # training checkpoint, then derive from num_patches as a last resort.
    saved_args = {}
    args_path = os.path.join(os.path.dirname(checkpoint_path), 'args.json')
    if os.path.isfile(args_path):
        with open(args_path) as fp:
            saved_args = json.load(fp)
        img_size    = saved_args['img_size']
        patch_size  = saved_args['patch_size']
        in_channels = saved_args['in_channels']
    elif 'args' in ckpt:
        saved_args  = ckpt['args']
        img_size    = saved_args['img_size']
        patch_size  = saved_args['patch_size']
        in_channels = saved_args['in_channels']
    else:
        # Derive patch_size from num_patches: (img_size/patch_size)^2 = num_patches
        # Assume square image; try common sizes
        patch_size  = None
        for ps in [8, 16, 32]:
            if num_patches == (256 // ps) ** 2:
                patch_size  = ps
                img_size    = 256
                in_channels = 1
                break
        if patch_size is None:
            raise RuntimeError(
                f"Cannot infer patch_size from num_patches={num_patches}. "
                "Ensure args.json exists next to the checkpoint."
            )

    # ── Infer proj_dim and head type from state dict / args.json ─────────────
    proj_dim  = head_state['fc2.weight'].shape[0]
    head_type = saved_args.get('proj_head_type', 'ln')
    # For BNProjectionHead the hidden dim is fc1's output; for ProjectionHead it equals embed_dim
    proj_hidden_dim = head_state['fc1.weight'].shape[0]

    # ── Build and load encoder ────────────────────────────────────────────────
    encoder = ViTEncoder(
        img_size    = img_size,
        patch_size  = patch_size,
        in_channels = in_channels,
        embed_dim   = embed_dim,
        num_layers  = num_layers,
        num_heads   = NUM_HEADS,
        mlp_dim     = mlp_dim,
    )

    # ── Inject LoRA if this is a LoRA checkpoint ──────────────────────────────
    # LoRA state dicts have 'blocks.N.attn.qkv.linear.weight' instead of
    # 'blocks.N.attn.qkv.weight'.  Detect by presence of lora_A keys.
    is_lora = any('lora_A' in k for k in enc_state)
    if is_lora:
        if not saved_args:
            raise RuntimeError(
                f"LoRA checkpoint detected but no args found at {args_path} "
                "or embedded in checkpoint. Cannot determine LoRA rank/alpha."
            )
        lora_rank    = saved_args['lora_rank']
        lora_alpha   = saved_args['lora_alpha']
        lora_targets = set(saved_args['lora_target_modules'])
        inject_lora(encoder, rank=lora_rank, alpha=lora_alpha,
                    target_modules=lora_targets)
        print(f"  LoRA detected : rank={lora_rank}, alpha={lora_alpha}, "
              f"targets={sorted(lora_targets)}")

    encoder.load_state_dict(enc_state)
    encoder.eval().to(device)

    # ── Build and load projection head ────────────────────────────────────────
    if head_type == 'bn':
        proj_head = BNProjectionHead(in_dim=embed_dim, hidden_dim=proj_hidden_dim, out_dim=proj_dim)
    else:
        proj_head = ProjectionHead(in_dim=embed_dim, out_dim=proj_dim)
    proj_head.load_state_dict(head_state)
    proj_head.eval().to(device)

    tau_agg = float(_tau_agg_raw)

    print(f"  Encoder   : embed_dim={embed_dim}, num_layers={num_layers}, "
          f"num_heads={NUM_HEADS}, mlp_dim={mlp_dim}")
    _head_desc = (f"{embed_dim}→{proj_hidden_dim}→{proj_dim} BN+ReLU"
                  if head_type == 'bn' else f"{embed_dim}→{proj_dim} LN+GELU")
    print(f"  Proj head : {_head_desc} (L2-normalised output)")
    print(f"  tau_agg   : {tau_agg:.4f}  (|tau_agg| = {abs(tau_agg):.4f})")

    return encoder, proj_head, tau_agg


# ─────────────────────────────────────────────────────────────────────────────
# Encoding
# ─────────────────────────────────────────────────────────────────────────────

@torch.no_grad()
def encode_all_zhat(
    encoder,
    proj_head,
    images: np.ndarray,
    batch_size: int,
    device: torch.device,
) -> np.ndarray:
    """
    Encode every image through encoder + proj_head → z_hat.

    Uses the CLS token (index 0) only, then passes it through the projection
    head which applies L2 normalisation as its final step.

    Args:
        images : (N, C, H, W) float32 numpy array, normalised to [-1, 1].

    Returns:
        Z_hat : (N, proj_dim) float32 numpy array with unit-norm rows.
    """
    encoder.eval()
    proj_head.eval()
    all_z = []

    for start in range(0, len(images), batch_size):
        batch     = torch.from_numpy(images[start : start + batch_size]).to(device)
        cls_token = encoder(batch, return_all_tokens=False)   # (B, d) — CLS only
        z_hat     = proj_head(cls_token)                      # (B, proj_dim) — L2-normalised
        all_z.append(z_hat.cpu().float().numpy())

    return np.concatenate(all_z, axis=0)   # (N, proj_dim)


# ─────────────────────────────────────────────────────────────────────────────
# Feather mixing — synthetic z_hat generation
# ─────────────────────────────────────────────────────────────────────────────

@torch.no_grad()
def generate_synthetic_zhat_feathered(
    ref_images_np: np.ndarray,
    encoder,
    proj_head,
    device: torch.device,
    n_synthetic: int,
    patch_size: int,
    margin: int,
    seed: int = 0,
) -> np.ndarray:
    """
    Generate n_synthetic z_hat embeddings from feathered pseudo-images.

    Each pseudo-image is constructed by randomly sampling patches from the R
    real reference images and softening patch boundaries with a feathering mask
    (see gasf_feather_mixing.generate_feathered_pseudo_image).  The pseudo-images
    are then encoded through encoder → CLS token → proj_head → z_hat, matching
    the same pipeline used for all real images.

    Args:
        ref_images_np : (R, C, H, W) float32 array, normalised to [-1, 1].
        encoder       : ViTEncoder in eval mode on device.
        proj_head     : ProjectionHead in eval mode on device.
        device        : Target torch device.
        n_synthetic   : Number of pseudo-images to generate.
        patch_size    : Feathering patch size in pixels (should match model patch_size).
        margin        : Feathering mask edge width in pixels.
        seed          : RNG seed for reproducibility.

    Returns:
        z_synth : (n_synthetic, proj_dim) float32 unit-norm array.
    """
    rng = np.random.default_rng(seed)

    pseudo_images = [
        generate_feathered_pseudo_image(ref_images_np, patch_size, margin, rng)
        for _ in range(n_synthetic)
    ]  # list of (C, H, W)

    batch     = torch.from_numpy(np.stack(pseudo_images, axis=0)).to(device)  # (N, C, H, W)
    cls_token = encoder(batch, return_all_tokens=False)   # (N, d) — CLS only
    z_synth   = proj_head(cls_token)                      # (N, proj_dim) — L2-normalised

    return z_synth.cpu().float().numpy()


# ─────────────────────────────────────────────────────────────────────────────
# Scoring functions  (numpy, operate on pre-encoded z_hat)
# All return scores in [-1, 1] where higher = more genuine.
# Converted to distance = 1 - score for compute_eer.
# ─────────────────────────────────────────────────────────────────────────────

def mean_cosine_score(z_q: np.ndarray, z_refs: np.ndarray) -> np.ndarray:
    """
    (1/R) * Σ_r cos(z_q, z_r).

    Since z_hat rows are unit-norm, cosine similarity = dot product.

    Args:
        z_q    : (N, d) unit-norm query embeddings
        z_refs : (R, d) unit-norm reference embeddings
    Returns:
        scores : (N,)
    """
    return (z_q @ z_refs.T).mean(axis=1)       # (N, R) → (N,)


def softmax_cosine_score(
    z_q: np.ndarray,
    z_refs: np.ndarray,
    tau_agg: float,
) -> np.ndarray:
    """
    Σ_r softmax(cos(z_q, z_r) / |τ_agg|) · cos(z_q, z_r).

    References similar to the query receive higher weight.
    Reduces influence of outlier enrolled signatures.
    Uses the τ_agg value trained by the model's aggregation consistency loss.

    Args:
        z_q    : (N, d) unit-norm query embeddings
        z_refs : (R, d) unit-norm reference embeddings
        tau_agg: trained aggregation temperature scalar
    Returns:
        scores : (N,)
    """
    tau  = abs(tau_agg) + 1e-4              # mirror model's .abs().clamp(min=1e-4)
    sims = z_q @ z_refs.T                   # (N, R)

    # Numerically stable softmax
    logits  = sims / tau                    # (N, R)
    logits -= logits.max(axis=1, keepdims=True)
    weights = np.exp(logits)
    weights /= weights.sum(axis=1, keepdims=True)   # (N, R)

    return (weights * sims).sum(axis=1)     # (N,)


def proto_cosine_score(z_q: np.ndarray, z_refs: np.ndarray) -> np.ndarray:
    """
    cos(z_q,  normalise(mean(z_refs))).

    Computes a single normalised prototype first, then scores.
    When R is small and one reference is an outlier, the outlier's influence
    is reduced by the normalisation (the prototype is pulled towards the
    majority direction, and normalisation does not amplify the outlier further).

    Args:
        z_q    : (N, d) unit-norm query embeddings
        z_refs : (R, d) unit-norm reference embeddings
    Returns:
        scores : (N,)
    """
    proto      = z_refs.mean(axis=0)                # (d,)  — not unit-norm
    proto_norm = np.linalg.norm(proto)
    if proto_norm > 1e-8:
        proto = proto / proto_norm                   # (d,)  — normalised
    return z_q @ proto                               # (N,)


# ─────────────────────────────────────────────────────────────────────────────
# Data loading  (mirrors run_inference.py exactly)
# ─────────────────────────────────────────────────────────────────────────────

def _is_genuine(fname: str) -> bool:
    parts = str(fname).lower().split('_')
    if len(parts) >= 2:
        return parts[1] == 'g'
    return True


def load_test_data(data_path: str):
    """
    Load the test .npz and build per-writer index maps.

    Returns:
        images    : (N, C, H, W) float32, normalised to [-1, 1]
        w2genuine : writer_id -> list of genuine array indices (full list)
        w2forged  : writer_id -> list of forged  array indices
    """
    data       = np.load(data_path, allow_pickle=True)
    images     = data['gasf_data'].astype(np.float32)
    file_names = data['file_names']

    img_min, img_max = images.min(), images.max()
    if img_max - img_min > 1e-6:
        images = 2.0 * (images - img_min) / (img_max - img_min) - 1.0

    w2genuine: dict = defaultdict(list)
    w2forged:  dict = defaultdict(list)
    for i, fname in enumerate(file_names):
        wid = str(fname).split('_')[0]
        if _is_genuine(fname):
            w2genuine[wid].append(i)
        else:
            w2forged[wid].append(i)

    return images, dict(w2genuine), dict(w2forged)


# ─────────────────────────────────────────────────────────────────────────────
# Evaluation
# ─────────────────────────────────────────────────────────────────────────────

def run_cosine_evaluation(
    Z_hat: np.ndarray,
    w2genuine: dict,
    w2forged:  dict,
    R_enroll:  int,
    tau_agg:   float,
    images: np.ndarray = None,
    encoder=None,
    proj_head=None,
    device: torch.device = None,
    patch_size: int = 16,
    n_synthetic: int = 18,
    feather_margin: int = 4,
) -> dict:
    """
    Evaluate all writers with cosine scoring variants.

    For each writer:
      Enrollment  = z_hat[gen_idx[:R_enroll]]       (R, d)
      Genuine     = z_hat[gen_idx[R_enroll:]]       (N_g, d)
      Forged      = z_hat[forg_idx]                 (N_f, d)

    When images/encoder/proj_head are provided, also runs feather_* variants
    that augment each writer's enrollment with n_synthetic pseudo-images
    generated by feather mixing the R real reference images.

    Scores are converted to distances via  dist = 1 - score  so that
    the existing compute_eer (which expects distances) works unchanged.

    Returns:
        dict  variant_name -> list of per-writer result dicts
    """
    use_feather = (images is not None and encoder is not None
                   and proj_head is not None and device is not None)

    base_variants   = ['mean_cosine', 'softmax_cosine', 'proto_cosine']
    feather_variants = (
        ['feather_mean_cosine', 'feather_softmax_cosine', 'feather_proto_cosine']
        if use_feather else []
    )
    all_variants = base_variants + feather_variants
    results      = {v: [] for v in all_variants}

    for writer_id, gen_idx in w2genuine.items():
        if len(gen_idx) <= R_enroll:
            continue                                    # not enough genuine samples
        forg_idx = w2forged.get(writer_id, [])
        if len(forg_idx) == 0:
            continue

        z_refs = Z_hat[gen_idx[:R_enroll]]              # (R, d)
        z_gen  = Z_hat[gen_idx[R_enroll:]]              # (N_g, d)
        z_forg = Z_hat[forg_idx]                        # (N_f, d)

        # ── Feather-augmented enrollment (R + n_synthetic embeddings) ─────────
        if use_feather:
            ref_images_np = images[gen_idx[:R_enroll]]  # (R, C, H, W)
            z_synth = generate_synthetic_zhat_feathered(
                ref_images_np, encoder, proj_head, device,
                n_synthetic, patch_size, feather_margin,
            )
            z_refs_aug = np.concatenate([z_refs, z_synth], axis=0)  # (R + N, d)

        for variant in all_variants:
            # Select which enrollment set and which scoring fn to use
            if variant.startswith('feather_'):
                z_e = z_refs_aug
                base = variant[len('feather_'):]
            else:
                z_e  = z_refs
                base = variant

            if base == 'mean_cosine':
                s_gen  = mean_cosine_score(z_gen,  z_e)
                s_forg = mean_cosine_score(z_forg, z_e)
            elif base == 'softmax_cosine':
                s_gen  = softmax_cosine_score(z_gen,  z_e, tau_agg)
                s_forg = softmax_cosine_score(z_forg, z_e, tau_agg)
            else:   # proto_cosine
                s_gen  = proto_cosine_score(z_gen,  z_e)
                s_forg = proto_cosine_score(z_forg, z_e)

            # Convert cosine score → distance  (higher score = lower dist = genuine)
            d_gen  = (1.0 - s_gen).astype(np.float32)
            d_forg = (1.0 - s_forg).astype(np.float32)

            eer, tau_star = compute_eer(d_gen, d_forg)

            results[variant].append({
                'writer_id'          : writer_id,
                'n_genuine_queries'  : len(d_gen),
                'n_forged_queries'   : len(d_forg),
                'eer'                : eer,
                'tau_star'           : tau_star,
                'mean_genuine_score' : float(s_gen.mean()),
                'mean_forged_score'  : float(s_forg.mean()),
                'mean_genuine_dist'  : float(d_gen.mean()),
                'mean_forged_dist'   : float(d_forg.mean()),
            })

    return results


# ─────────────────────────────────────────────────────────────────────────────
# Reporting
# ─────────────────────────────────────────────────────────────────────────────

def print_results(results_by_variant: dict) -> None:
    print()
    print("=" * 72)
    print("  COSINE INFERENCE RESULTS  (DeepSignDB test set)")
    print("=" * 72)
    print(f"  {'Variant':<22}  {'Writers':>7}  {'Mean EER':>9}  "
          f"{'±Std':>7}  {'Median':>8}")
    print("  " + "-" * 60)

    for variant, results in results_by_variant.items():
        if not results:
            print(f"  {variant:<22}  (no results)")
            continue
        s = aggregate(results)
        print(
            f"  {variant:<22}  {s['n_writers']:>7}  "
            f"{s['mean_eer']*100:>8.2f}%  "
            f"{s['std_eer']*100:>6.2f}%  "
            f"{s['median_eer']*100:>7.2f}%"
        )

    print("=" * 72)
    print()
    print("  Baseline to compare against: run_inference.py")
    print("  (patch GAP 384-dim + Mahalanobis)")
    print()
    print("  EER gap = baseline − best cosine variant")
    print("  → estimates fraction of error from feature+metric mismatch")
    print("  → residual = encoder capacity limitation (not fixable without retraining)")


def print_score_separation(results_by_variant: dict) -> None:
    """Print mean genuine/forged scores per variant to visualise separation."""
    print()
    print("  Score separation (higher genuine score = better discriminability):")
    print(f"  {'Variant':<22}  {'μ genuine':>11}  {'μ forged':>10}  {'gap':>7}")
    print("  " + "-" * 55)
    for variant, results in results_by_variant.items():
        if not results:
            continue
        gen_scores  = np.array([r['mean_genuine_score'] for r in results])
        forg_scores = np.array([r['mean_forged_score']  for r in results])
        mu_gen  = gen_scores.mean()
        mu_forg = forg_scores.mean()
        print(
            f"  {variant:<22}  {mu_gen:>10.4f}  {mu_forg:>9.4f}  "
            f"{mu_gen - mu_forg:>6.4f}"
        )


# ─────────────────────────────────────────────────────────────────────────────
# Main
# ─────────────────────────────────────────────────────────────────────────────

def main():
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Device : {device}")
    if torch.cuda.is_available():
        print(f"GPU    : {torch.cuda.get_device_name(0)}")

    os.makedirs(OUTPUT_DIR, exist_ok=True)

    # ── Load model ────────────────────────────────────────────────────────────
    print(f"\n[1] Loading model from:\n    {CHECKPOINT_PATH}")
    encoder, proj_head, tau_agg = load_model(CHECKPOINT_PATH, device)

    # Resolve patch_size for feather mixing (inferred from args.json during load_model)
    args_path = os.path.join(os.path.dirname(CHECKPOINT_PATH), 'args.json')
    if os.path.isfile(args_path):
        with open(args_path) as fp:
            _args = json.load(fp)
        _patch_size = _args.get('patch_size', 16)
    else:
        # Fall back: infer from pos_embed shape stored in loaded checkpoint
        ckpt = torch.load(CHECKPOINT_PATH, map_location='cpu')
        n_patches = ckpt['encoder']['pos_embed'].shape[1] - 1
        _patch_size = 256 // int(n_patches ** 0.5)
    feather_margin = FEATHER_MARGIN if FEATHER_MARGIN is not None else _patch_size // 4
    print(f"  Feather mixing : {'ON' if USE_FEATHER_MIXING else 'OFF'}  "
          f"(patch_size={_patch_size}, margin={feather_margin}, n_synthetic={N_SYNTHETIC})")

    # ── Load test data ────────────────────────────────────────────────────────
    print(f"\n[2] Loading test data from:\n    {TEST_DATA_PATH}")
    images, w2genuine, w2forged = load_test_data(TEST_DATA_PATH)
    n_query_gen  = sum(max(0, len(v) - R_ENROLL) for v in w2genuine.values())
    n_query_forg = sum(len(v) for v in w2forged.values())
    print(f"    Total images         : {len(images)}")
    print(f"    Writers              : {len(w2genuine)}")
    print(f"    Genuine query images : {n_query_gen}")
    print(f"    Forged  query images : {n_query_forg}")

    # ── Encode all images in one pass ─────────────────────────────────────────
    print(f"\n[3] Encoding all {len(images)} images  (encoder → CLS → proj_head → z_hat) ...")
    Z_hat = encode_all_zhat(encoder, proj_head, images, ENCODE_BATCH_SIZE, device)

    # Sanity check: rows should be unit-norm
    norms = np.linalg.norm(Z_hat, axis=1)
    print(f"    Z_hat shape : {Z_hat.shape}")
    print(f"    Norm check  : mean={norms.mean():.5f}  std={norms.std():.5f}  "
          f"(expect 1.00000, 0.00000)")

    # ── Evaluate cosine variants (+ feather variants if enabled) ─────────────
    n_variants = 3 + (3 if USE_FEATHER_MIXING else 0)
    print(f"\n[4] Evaluating {n_variants} cosine scoring variants  (R_enroll={R_ENROLL}) ...")
    results_by_variant = run_cosine_evaluation(
        Z_hat, w2genuine, w2forged, R_ENROLL, tau_agg,
        images=images if USE_FEATHER_MIXING else None,
        encoder=encoder if USE_FEATHER_MIXING else None,
        proj_head=proj_head if USE_FEATHER_MIXING else None,
        device=device if USE_FEATHER_MIXING else None,
        patch_size=_patch_size,
        n_synthetic=N_SYNTHETIC,
        feather_margin=feather_margin,
    )

    print_results(results_by_variant)
    print_score_separation(results_by_variant)

    # ── Save results ──────────────────────────────────────────────────────────
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    out = {
        'timestamp'         : timestamp,
        'checkpoint'        : CHECKPOINT_PATH,
        'R_enroll'          : R_ENROLL,
        'tau_agg'           : tau_agg,
        'n_images'          : len(images),
        'zhat_shape'        : list(Z_hat.shape),
        'norm_mean'         : float(norms.mean()),
        'feather_mixing'    : USE_FEATHER_MIXING,
        'n_synthetic'       : N_SYNTHETIC if USE_FEATHER_MIXING else 0,
        'feather_margin'    : feather_margin if USE_FEATHER_MIXING else None,
        'feather_patch_size': _patch_size if USE_FEATHER_MIXING else None,
        'variants'          : {},
    }
    for variant, results in results_by_variant.items():
        out['variants'][variant] = {
            'summary'    : aggregate(results),
            'per_writer' : sorted(results, key=lambda r: r['writer_id']),
        }

    json_path = os.path.join(OUTPUT_DIR, f'cosine_results_{timestamp}.json')
    with open(json_path, 'w') as fp:
        json.dump(out, fp, indent=2)
    print(f"\n  Results saved to: {json_path}")


if __name__ == '__main__':
    main()
